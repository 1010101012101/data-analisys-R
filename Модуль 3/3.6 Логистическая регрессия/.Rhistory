ggplot(swiss, aes(x = Examination, y = Fertility)) +
geom_point() +
geom_smooth()
ggplot(swiss, aes(x = Examination, y = Fertility, col = religious)) +
geom_point()
ggplot(swiss, aes(x = Examination, y = Fertility, col = religious)) +
geom_point()  +
geom_smooth()
ggplot(swiss, aes(x = Examination, y = Fertility, col = religious)) +
geom_point()
ggplot(swiss, aes(x = Examination, y = Fertility, col = religious)) +
geom_point()  +
geom_smooth()
ggplot(swiss, aes(x = Examination, y = Fertility, col = religious)) +
geom_point()  +
geom_smooth(method = 'lm')
fit5 <- lm(Fertility ~ religious*Infant.Mortality*Examination, data = swiss)
summary(fit5)
fit5 <- lm(Fertility ~ religious*Infant.Mortality*Examination, data = swiss)
summary(fit5)
df_numeric  <- mtcars
df_numeric$am <- factor(df_numeric$am, labels = c('Automatic', 'Manual'))
model <- lm(mpg ~ wt*am, df_numeric)
summary(model)
confint(model)
View(df_numeric)
library(ggplot2)
my_plot <- ggplot()
ggplot(mtcars, aes(x = wt, y = mpg, col = am)) +
geom_point()  +
geom_smooth(method = 'lm')
ggplot(df_numeric, aes(x = wt, y = mpg, col = am)) +
geom_point()  +
geom_smooth(method = 'lm')
lot(df_numeric, aes(x = wt, y = mpg, col = am)) +
g
ggplot(df_numeric, aes(x = wt, y = mpg, col = am)) +
geom_smooth(method = 'lm')
df_numeric  <- mtcars
df <-df_numeric[,c(1,3:6)]
model <- lm(wt ~ mpg+disp+drat+disp, df) #mpg*disp*drat*disp
summary(model)$adj.r.squared
summary(model)
model <- lm(wt ~ mpg+disp+drat+hp, df) #mpg*disp*drat*disp
summary(model)
model <- lm(wt ~ disp, df) #mpg*disp*drat*disp
summary(model)
model <- lm(wt ~ mpg*disp*drat*disp, df) #mpg*disp*drat*disp
summary(model)
model <- lm(wt ~ mpg*disp, df) #mpg*disp*drat*disp
summary(model)
model <- lm(wt ~ mpg+disp, df) #mpg*disp*drat*disp
summary(model)
model <- lm(wt ~ drat+disp, df) #mpg*disp*drat*disp
summary(model)
model <- lm(wt ~ drat*disp, df) #mpg*disp*drat*disp
summary(model)
swiss <- data.frame(swiss)
fit_reduced1 <- lm(Fertility ~ Infant.Mortality + Examination + Catholic + Education, data = swiss)
summary(fit_reduced1)
anova(fit_full, fit_reduced1)
fit_reduced2 <- lm(Fertility ~ Infant.Mortality + Education + Catholic + Agriculture, data = swiss)
summary(fit_reduced2)
anova(fit_full, fit_reduced2)
fit_full <- lm(Fertility ~ ., data = swiss)
anova(fit_full, fit_reduced1)
anova(fit_full, fit_reduced2)
optimal_fit <-  step(fit_full, direction = 'backward')
fit_reduced2 <- lm(Fertility ~ Infant.Mortality + Education + Catholic + Agriculture, data = swiss)
step(fit_full, direction = 'backward')
summary(optimal_fit)
fit_full <- lm(wt ~ ., df) #mpg*disp*drat*disp
df_numeric  <- mtcars
df <-df_numeric[,c(1,3:6)]
fit_full <- lm(wt ~ ., df) #mpg*disp*drat*disp
optimal_fit <-  step(fit_full, direction = 'backward')
summary(optimal_fit)
model_full <- lm(rating ~ ., data = attitude)
model_null <- lm(rating ~ 1, data = attitude)
summary(model_full)
optimal_fit <-  step(fit_full, direction = 'backward', scope = list(lower = model_null, upper = model_full))
optimal_fit <-  step(fit_full, direction = 'backward', scope = list(lower = model_full, upper = model_null))
data <- attitude
View(data)
model_full <- lm(rating ~ ., data = attitude)
model_null <- lm(rating ~ 1, data = attitude)
optimal_fit <-  step(fit_full, direction = 'backward', scope = list(lower = model_full, upper = model_null))
optimal_fit <-  step(model_full, direction = 'backward', scope = list(lower = model_full, upper = model_null))
summary(optimal_fit)
optimal_fit <-  step(model_full, direction = 'backward', scope = list(lower = model_null, upper = model_full))
summary(optimal_fit)
scope = list(lower = model_null, upper = model_full)
anova(model_full, optimal_fit)
data <- LifeCycleSavings
model <- lm(sr ~ ., data)
summary(model)
?formula
model <- lm(sr ~ (pop15*pop15*dpi*ddpi)^2, data)
summary(model)
data <- LifeCycleSavings
setwd("~/R/Анализ данных в R/Модуль 3/3.4 Диагностика модели")
library(ggplot2)
data(swiss)
str(swiss)
pairs(swiss)
ggplot(swiss, aes(x = Examination, y = Education)) +
geom_point()
ggplot(swiss, aes(x = Examination, y = Education)) +
geom_point() +
geom_smooth(method = 'lm')
ggplot(swiss, aes(x = Examination)) +
geom_histogram()
ggplot(swiss, aes(x = Education)) +
geom_histogram()
ggplot(swiss, aes(x = log(Education)) +
geom_histogram()
geom_histogram()
ggplot(swiss, aes(x = log(Education)) +
geom_histogram()
ggplot(swiss, aes(x = Examination)) +
geom_histogram()
ggplot(swiss, aes(x = Examination)) +
geom_histogram()
ggplot(swiss, aes(x = log(Education)) +
geom_histogram()
geom_histogram()
my_vector <- c(0.027, 0.079, 0.307, 0.098, 0.021, 0.091, 0.322, 0.211, 0.069, 0.261, 0.241, 0.166, 0.283, 0.041, 0.369, 0.167, 0.001, 0.053, 0.262, 0.033, 0.457, 0.166, 0.344, 0.139, 0.162, 0.152, 0.107, 0.255, 0.037, 0.005, 0.042, 0.220, 0.283, 0.050, 0.194, 0.018, 0.291, 0.037, 0.085, 0.004, 0.265, 0.218, 0.071, 0.213, 0.232, 0.024, 0.049, 0.431, 0.061, 0.523)
shapiro.test(my_vector)
shapiro.test(log(my_vector))
shapiro.test(1/(my_vector))
shapiro.test(sqrt(my_vector))
scale(my_vector)
my_vector <- c(0.027, 0.079, 0.307, 0.098, 0.021, 0.091, 0.322, 0.211, 0.069, 0.261, 0.241, 0.166, 0.283, 0.041, 0.369, 0.167, 0.001, 0.053, 0.262, 0.033, 0.457, 0.166, 0.344, 0.139, 0.162, 0.152, 0.107, 0.255, 0.037, 0.005, 0.042, 0.220, 0.283, 0.050, 0.194, 0.018, 0.291, 0.037, 0.085, 0.004, 0.265, 0.218, 0.071, 0.213, 0.232, 0.024, 0.049, 0.431, 0.061, 0.523)
new_vect <- scale(my_vector)
View(new_vect)
test_df <- mtcars[,c(1,3)]
View(test_df)
new_df <- c(x[,1],x[,2])
new_df <- c(test_df[,1], test_df[,2])
new_df <- [test_df[,1], test_df[,2]]
new_df <- (test_df[,1], test_df[,2]])
new_df$v1 <- test_df[,1]
test_df[,1]
new_df[,1] <- test_df[,1]
new_df <- data.frame(v1 = test_df[,1], v2 = test_df[,2])
x <- mtcars[,c(1,3)]
new_df <- data.frame(v1 = x[,1], v2 = x[,2])
new_df <- data.frame(v1 = scale(x[,1]), v2 = (x[,2]))
new_df <- data.frame(v1 = scale(x[,1]), v2 = scale(x[,2]))
model <- lm(v1 ~ v2, new_df)
model$coefficients
x <- mtcars[,1:6]
View(x)
apply(x, 2, shapiro.test)
a <- apply(x, 2, vshapiro.test)
a <- apply(x, 2, shapiro.test)
a
a$mpg
a$mpg$p.value
a[1]$p.value
a[,1]$p.value
a(1)$p.value
a[1]$p.value
a[1,]$p.value
a$p.value
vect_of_name <- apply(x, 2, names)
vect_of_name <- apply(x, 1, names)
for (name in vect_of_name){
name
}
for (name in vect_of_name){
print(name)
}
View(vect_of_name)
vect_of_name[,1]
for (name in vect_of_name[,1]){
print(name)
}
for (name in vect_of_name[,1]){
my_vector <- a$name$p.value
}
for (name in vect_of_name[,1]){
my_vector <- a$[]$p.value
}
my_vector <- a$[,,]$p.value
my_vector <- a$[,]$p.value
for (i in length(vect_of_name[,1])){
print(i)
}
for (i in 1:length(vect_of_name[,1])){
print(i)
}
for (i in 1:length(vect_of_name[,1])){
a <- union(a, shapiro.test(x[,i]))
}
x <- mtcars[,1:6]
vect_of_name <- apply(x, 1, names)
a <- apply(x, 2, shapiro.test)
for (i in 1:length(vect_of_name[,1])){
my_vec <- append(my_vec, shapiro.test(x[,i]))
}
my_vec <- 0
for (i in 1:length(vect_of_name[,1])){
my_vec <- append(my_vec, shapiro.test(x[,i]))
}
res <- shapiro.test(x[,i])
my_vec <- append(my_vec, res$p.value)
vect_of_name <- apply(x, 1, names)
a <- apply(x, 2, shapiro.test)
my_vec <- 0
for (i in 1:length(vect_of_name[,1])){
res <- shapiro.test(x[,i])
my_vec <- append(my_vec, res$p.value)
}
vect_of_name <- apply(x, 1, names)
a <- apply(x, 2, shapiro.test)
for (i in 1:length(vect_of_name[,1])){
res <- shapiro.test(x[,i])
my_vec <- append(my_vec, res$p.value)
}
x <- mtcars[,1:6]
vect_of_name <- apply(x, 1, names)
a <- apply(x, 2, shapiro.test)
for (i in 1:length(vect_of_name[,1])){
res <- shapiro.test(x[,i])
my_vec <- append(my_vec, res$p.value)
}
x <- mtcars[,1:6]
vect_of_name <- apply(x, 1, names)
a <- apply(x, 2, shapiro.test)
for (i in 1:length(vect_of_name[,1])){
res <- shapiro.test(x[,i])
if (i == 0) {my_vec <- res$p.value}
else{
my_vec <- append(my_vec, res$p.value)
}
}
x <- mtcars[,1:6]
vect_of_name <- apply(x, 1, names)
a <- apply(x, 2, shapiro.test)
for (i in 1:length(vect_of_name[,1])){
res <- shapiro.test(x[,i])
if (i == 1) {my_vec <- res$p.value}
else{
my_vec <- append(my_vec, res$p.value)
}
}
names(my_vector) <- vect_of_name[,1]
names(my_vec) <- vect_of_name[,1]
my_vec
ggplot(swiss, aes(x = Examination, y = Education)) +
geom_point() +
geom_smooth()
lm1 <- lm(Education ~ Examination, swiss)
summary(lm1)
swiss$Examination_squared <- (swiss$Examination)^2
lm2 <- lm(Education ~ Examination + Examination_squared, swiss)
summary(lm2)
anova(lm2, lm1)
swiss$lm1_fitted <- lm1$fitted.values
swiss$lm2_fitted <- lm2$fitted.values
swiss$lm1_resid <- lm1$residuals
swiss$lm2_resid <- lm2$residuals
swiss$obs_number <- 1:nrow(swiss)
install.packages("gvlma")
setwd("~/R/Анализ данных в R/Модуль 3/3.5 Продолжение")
table <- read.csv("homocs.csv")
table <- read.csv("homosc.csv")
View(table)
model <- lm( DV~IV, table)
gvlma(model)
library("gvlma", lib.loc="~/R/win-library/3.2")
gvlma(model)
res <- gvlma(model)
summary(res)
table$model_fitted <- model$fitted.values
table$model_resid <- model$residuals
ggplot(table, aes(x = model_fitted, y = model_resid)) +
geom_point(size = 3)
ggplot(swiss, aes(x = lm1_resid)) +
geom_histogram(binwidth = 4, fill = 'white', col = 'black')
qqnorm(lm2$residuals)
qqline(lm2$residuals)
qqline(lm2$residuals)
qqnorm(lm2$residuals)
shapiro.test(lm2$residuals)
fit <- lm(mpg ~ wt, mtcars)
data <- data.frame(fit_v = fit$fitted.values,res = fit$residuals)
test <- shapiro.test(data$res)
color <- ifelse((test$p.value < 0.05),"red","green")
test$p.value
gplot(data, aes(x = res)) +
geom_histogram(binwidth = 4, fill = 'white', col = color)
library(ggplot2)
ggplot(data, aes(x = res)) +
geom_histogram(binwidth = 4, fill = 'white', col = color)
ggplot(data, aes(x = res)) +
geom_histogram(binwidth = 4, fill = color)
ggplot(swiss, aes(x = lm2_resid)) +
geom_histogram(binwidth = 4, fill = 'white', col = 'black')
ggplot(data, aes(x = res)) +
geom_histogram(binwidth = 1, fill = color)
ggplot(data, aes(x = res)) +
geom_histogram(binwidth = 0.5, fill = color)
ggplot(data, aes(x = res)) +
geom_histogram(binwidth = 0.1, fill = color)
ggplot(data, aes(x = res)) +
geom_histogram(binwidth = 0.2, fill = color)
ggplot(data, aes(x = res)) +
geom_histogram(binwidth = 0.4, fill = color)
ggplot(data, aes(x = res)) +
geom_histogram(binwidth = 0.3, fill = color)
ggplot(data, aes(x = res)) +
geom_histogram(binwidth = 0.5, fill = color)
fit <- lm(mpg ~ disp, mtcars)
data <- data.frame(fit_v = fit$fitted.values,res = fit$residuals)
test <- shapiro.test(data$res)
color <- ifelse((test$p.value < 0.05),"red","green")
plot <- ggplot(data, aes(x = res)) +
geom_histogram(binwidth = 0.5, fill = color)
plot
ggplot(data, aes(x = res)) +
geom_histogram(fill = color)
library(psych)
filtered.cor <- function(x){
nums <- sapply(x, is.numeric)
a1 <- x[ , nums]
r <- corr.test(a1)
a <- r$r
m <- max(abs(a[a!=1]))
k <- 0
for (mi in a){
if (mi == m){
k <- k+1
}
}
if(k==2) return(m) else  return(m*(-1))
}
filtered.cor(iris)
ifelse((k==2),m,(m*(-1)))
x <- iris
nums <- sapply(x, is.numeric)
a1 <- x[ , nums]
r <- corr.test(a1)
a <- r$r
m <- max(abs(a[a!=1]))
k <- 0
for (mi in a){
if (mi == m){
k <- k+1
}
}
ifelse((k==2),m,(m*(-1)))
corr.test(a1)
x$new <- x$Sepal.Width*10
nums <- sapply(x, is.numeric)
a1 <- x[ , nums]
corr.test(a1)
r$r
colnames(r$r)
r$r
r$r[,]
r$r[,1]
r$r[1,1]
r$r[1,]
r$r[,1]
length(colnames(r$r))
length(rownames(r$r))
r$r[,1]
r$r[2,3]
colnames(r$r[2,3])
colname(r$r[2,3])
colnames(r$r)
colnames(r$r[1,])
colnames(r$r(1))
colnames(r$r[1])
col_name <- colnames(r$r)
row_name <- rownames(r$r)
col_name[1]
result <- c(col_name[i],row_name[j])
x <- iris
x$new <- x$Sepal.Width*10
nums <- sapply(x, is.numeric)
a1 <- x[ , nums]
r <- corr.test(a1)
a <- r$r
max <- 0
col_name <- colnames(r$r)
row_name <- rownames(r$r)
for (i in 1:length(rownames(r$r)))
{
for (j in 1:length(colnames(r$r)))
{
if (i!=j)
{
if (r$r[i,j] > max){
max <- r$r[i,j]
result <- c(row_name[i],col_name[j])
}
}
j <- j+1
}
i <- i+1
}
View(x)
r
setwd("~/R/Анализ данных в R/Модуль 3/3.6 Логистическая регрессия")
library(ggplot2)
my_df <- read.csv("train.csv", sep=";")
ggplot(my_df, aes(read, math, col = gender))+
geom_point(size = 5)+
facet_grid(.~hon)+
theme(axis.text=element_text(size=25),
axis.title=element_text(size=25,face="bold"))
ggplot(my_df, aes(read, math, col = gender))+
geom_point(size = 4)+
facet_grid(.~hon)+
theme(axis.text=element_text(size=25),
axis.title=element_text(size=25,face="bold"))
fit  <- glm(hon ~ read + math + gender, my_df, family = "binomial")
summary(fit)
my_df$prob  <- predict(object = fit, type = "response")
View(my_df)
data <- mtcars
model <- glm(am~disp+vs+mpg, data, family = "binomial")
summary(model)
model$coefficients
print(model$coefficients)
library("ggplot2")
ggplot(data = ToothGrowth, aes(x = supp,y = len))+geom_boxplot(fill = dose)
ggplot(data = ToothGrowth, aes(x = supp,y = len, fill = dose))+geom_boxplot())
ggplot(data = ToothGrowth, aes(x = supp,y = len, fill = dose))+geom_boxplot()
ggplot(data = ToothGrowth, aes(x = supp,y = len))+geom_boxplot(aes(fill = dose))
data <- ToothGrowth
View(data)
ggplot(data = ToothGrowth, aes(x = supp,y = len))+geom_boxplot(ToothGrowth,aes(fill = dose))
ggplot(data = ToothGrowth, aes(x = supp,y = len))+geom_boxplot(aes(color = dose))
ggplot(data = ToothGrowth, aes(x = supp,y = len))+geom_boxplot(aes(color = dose))
ggplot(data = ToothGrowth, aes(x = supp,y = len))+geom_boxplot()
obj <- ggplot(data = ToothGrowth, aes(x = supp,y = len))
obj + +geom_boxplot(aes(fill = dose))
obj +geom_boxplot(aes(fill = dose))
obj + geom_boxplot()
obj + geom_boxplot(aes(fill = dose))
obj + geom_boxplot(fill = "white", colour = "#3366FF")
obj + geom_boxplot(fill = "green", colour = "#3366FF")
obj + geom_boxplot(fill = ToothGrowth$dose, colour = "#3366FF")
obj + geom_boxplot(aes(fill = ToothGrowth$dose), colour = "#3366FF")
data$dose <- as.factor(data$dose)
obj + geom_boxplot(aes(fill = data$dose), colour = "#3366FF")
ToothGrowth$dose <- as.factor(ToothGrowth$dose)
obj <- ggplot(data = ToothGrowth, aes(x = supp,y = len))
obj + geom_boxplot(aes(fill = dose))
library(ROCR)
install.packages("ROCR")
pred_fit <- prediction(my_df$prob, my_df$hon)
perf_fit <- performance(pred_fit,"tpr","fpr")
library(ROCR)
pred_fit <- prediction(my_df$prob, my_df$hon)
my_df <- read.csv("train.csv", sep=";")
fit  <- glm(hon ~ read + math + gender, my_df, family = "binomial")
my_df$prob  <- predict(object = fit, type = "response")
pred_fit <- prediction(my_df$prob, my_df$hon)
perf_fit <- performance(pred_fit,"tpr","fpr")
plot(perf_fit, colorize=T , print.cutoffs.at = seq(0,1,by=0.1))
table <- read.csv("data.csx"v)
table <- read.csv("data.csv")
View(table)
table$admit <- as.factor(table$admit)
table$rank <- as.factor(table$rank)
new_table <- subset(table, !is.na(table$admit))
View(new_table)
new_table_no_data<- subset(table, is.na(table$admit))
model <- glm(admit~rank+gpa, new_table, family = "binomial_regression.R")
model <- glm(admit~rank+gpa, new_table, family = "binomial")
fit <- glm(admit~rank+gpa, new_table, family = "binomial")
exp(fit$coefficients)
head(predict(object = fit))
head(predict(object = fit, type = "response"))
new_table_no_data$pred  <- predict(fit, newdata = new_table_no_data, type = "response")
View(new_table_no_data)
new_table_no_data$pred_resp  <- (ifelse(new_table_no_data$pred >= 0.4, 1, 0))
length(new_table_no_data$pred_resp)
new_table_no_data$pred_resp[1]
new_table_no_data$pred_resp[100]
count <- 0
for (i in 1:length(new_table_no_data$pred_resp))
{
if (new_table_no_data$pred_resp[i] == 1) count <- count+1
}
fit <- glm(admit~rank*gpa, new_table, family = "binomial")
new_table_no_data$pred  <- predict(fit, newdata = new_table_no_data,
new_table_no_data$pred_resp  <- (ifelse(new_table_no_data$pred >= 0.4, 1, 0))
count <- 0
for (i in 1:length(new_table_no_data$pred_resp))
{
if (new_table_no_data$pred_resp[i] == 1) count <- count+1
}
count <- 0
for (i in 1:length(new_table_no_data$pred_resp))
{
if (new_table_no_data$pred_resp[i] == 1) count <- count+1
}
fit <- glm(admit~rank*gpa, new_table, family = "binomial")
new_table_no_data$pred  <- predict(fit, newdata = new_table_no_data,
type = "response")
new_table_no_data$pred_resp  <- (ifelse(new_table_no_data$pred >= 0.4, 1, 0))
count <- 0
for (i in 1:length(new_table_no_data$pred_resp))
{
if (new_table_no_data$pred_resp[i] == 1) count <- count+1
}
